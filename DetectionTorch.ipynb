{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f5121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\NLP\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS as GENSIM_STOPWORDS\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from collections import Counter\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to be run if punkt and stopwords have not been downloaded\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4befe3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and label the data\n",
    "df_true = pd.read_csv(\"True.csv\")\n",
    "df_fake = pd.read_csv(\"Fake.csv\")\n",
    "\n",
    "df_true['is_fake'] = 0\n",
    "df_fake['is_fake'] = 1\n",
    "\n",
    "df = pd.concat([df_true, df_fake]).reset_index(drop=True)\n",
    "df.drop(columns=['date'], inplace=True)\n",
    "df['original'] = df['title'] + ' ' + df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06ab02c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>is_fake</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>0</td>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>0</td>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>0</td>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>0</td>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>0</td>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE reported earl...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>1</td>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "      <td>21st Century Wire says It s a familiar theme. ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>1</td>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n",
       "      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "      <td>21st Century Wire says Al Jazeera America will...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>1</td>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>1</td>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      As U.S. budget fight looms, Republicans flip t...   \n",
       "1      U.S. military to accept transgender recruits o...   \n",
       "2      Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3      FBI Russia probe helped by Australian diplomat...   \n",
       "4      Trump wants Postal Service to charge 'much mor...   \n",
       "...                                                  ...   \n",
       "44893  McPain: John McCain Furious That Iran Treated ...   \n",
       "44894  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "44895  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n",
       "44896  How to Blow $700 Million: Al Jazeera America F...   \n",
       "44897  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "0      WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1      WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2      WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3      WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4      SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "...                                                  ...           ...   \n",
       "44893  21st Century Wire says As 21WIRE reported earl...   Middle-east   \n",
       "44894  21st Century Wire says It s a familiar theme. ...   Middle-east   \n",
       "44895  Patrick Henningsen  21st Century WireRemember ...   Middle-east   \n",
       "44896  21st Century Wire says Al Jazeera America will...   Middle-east   \n",
       "44897  21st Century Wire says As 21WIRE predicted in ...   Middle-east   \n",
       "\n",
       "       is_fake                                           original  \n",
       "0            0  As U.S. budget fight looms, Republicans flip t...  \n",
       "1            0  U.S. military to accept transgender recruits o...  \n",
       "2            0  Senior U.S. Republican senator: 'Let Mr. Muell...  \n",
       "3            0  FBI Russia probe helped by Australian diplomat...  \n",
       "4            0  Trump wants Postal Service to charge 'much mor...  \n",
       "...        ...                                                ...  \n",
       "44893        1  McPain: John McCain Furious That Iran Treated ...  \n",
       "44894        1  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...  \n",
       "44895        1  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...  \n",
       "44896        1  How to Blow $700 Million: Al Jazeera America F...  \n",
       "44897        1  10 U.S. Navy Sailors Held by Iranian Military ...  \n",
       "\n",
       "[44898 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542b96ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", '', text)\n",
    "    tokens = simple_preprocess(text)\n",
    "    stop_words = set(stopwords.words('english')).union(GENSIM_STOPWORDS)\n",
    "    return [word for word in tokens if word not in stop_words and len(word) > 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31aee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean'] = df['original'].apply(preprocess)\n",
    "df['clean_joined'] = df['clean'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d6830ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [budget, fight, looms, republicans, flip, fisc...\n",
       "1        [military, accept, transgender, recruits, mond...\n",
       "2        [senior, republican, senator, mueller, washing...\n",
       "3        [russia, probe, helped, australian, diplomat, ...\n",
       "4        [trump, wants, postal, service, charge, amazon...\n",
       "                               ...                        \n",
       "44893    [mcpain, john, mccain, furious, iran, treated,...\n",
       "44894    [justice, yahoo, settles, email, privacy, clas...\n",
       "44895    [sunnistan, allied, safe, zone, plan, territor...\n",
       "44896    [blow, million, jazeera, america, finally, cal...\n",
       "44897    [navy, sailors, held, iranian, military, signs...\n",
       "Name: clean, Length: 44898, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d465674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and vocab\n",
    "all_text = \" \".join(df['clean_joined'].tolist()).split()\n",
    "vocab = Counter(all_text)\n",
    "vocab = {word: i + 2 for i, (word, _) in enumerate(vocab.most_common(10000))}\n",
    "vocab['<PAD>'] = 0\n",
    "vocab['<UNK>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4213f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    return [vocab.get(word, vocab['<UNK>']) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dbf2024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['encoded'] = df['clean_joined'].apply(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ec86690",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 500\n",
    "\n",
    "def pad_seq(seq, maxlen):\n",
    "    return seq[:maxlen] + [vocab['<PAD>']] * max(0, maxlen - len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5c3f478",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['padded'] = df['encoded'].apply(lambda x: pad_seq(x, maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46d18775",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df['padded'].tolist(), df['is_fake'].tolist(), test_size=0.2, stratify=df['is_fake']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "774edd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = torch.tensor(texts, dtype=torch.long)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.texts[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd701d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = NewsDataset(x_train, y_train)\n",
    "test_ds = NewsDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ec0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        h_n = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n",
    "        x = self.dropout(h_n)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbaa4318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b743538c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x128 and 256x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m batch_x, batch_y \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mto(device), batch_y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n\u001b[0;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[18], line 16\u001b[0m, in \u001b[0;36mBiLSTMClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m _, (h_n, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x)\n\u001b[0;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(h_n)\n\u001b[1;32m---> 16\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x128 and 256x128)"
     ]
    }
   ],
   "source": [
    "model = BiLSTMClassifier(vocab_size=len(vocab), embed_dim=128, hidden_dim=128).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Early stopping and saving\n",
    "early_stop_patience = 2\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model_path = \"models/biltsm_fakenews.pt\"\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            val_loss += criterion(outputs, batch_y).item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        patience_counter = 0\n",
    "        print(\"Model improved. Saving model...\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(\"Early stop patience triggered...\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Evaluation\n",
    "preds, targets = [], []\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        outputs = model(batch_x)\n",
    "        preds.extend(outputs.cpu().numpy())\n",
    "        targets.extend(batch_y.numpy())\n",
    "\n",
    "pred_labels = [1 if p > 0.5 else 0 for p in preds]\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(targets, pred_labels))\n",
    "print(classification_report(targets, pred_labels, target_names=[\"Fake\", \"Real\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ecc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(targets, pred_labels)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
